{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Groq' from 'langchain.llms' (c:\\Users\\harsh\\Projects\\Python\\AIML\\.conda\\Lib\\site-packages\\langchain\\llms\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcassandra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cassandra\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndexWrapper\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings  \u001b[38;5;66;03m# You might need to adjust this if you switch embeddings as well\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Groq' from 'langchain.llms' (c:\\Users\\harsh\\Projects\\Python\\AIML\\.conda\\Lib\\site-packages\\langchain\\llms\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import Groq\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Switch if using a different embedding model\n",
    "from datasets import load_dataset\n",
    "import cassio\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Secrets for Astra DB and Groq\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:RJiHBlqgkeQpWjwjYNTEunoi:0878304bf3012b4b65478929ce8c4dc59de07b2793daa349900dd70fe114419c\"\n",
    "ASTRA_DB_ID = \"b2db8230-8846-4de4-8efa-0db38bda78b4\"\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "# Extract text from PDF\n",
    "pdfreader = PdfReader('temp.pdf')\n",
    "raw_text = ''\n",
    "for page in pdfreader.pages:\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content\n",
    "\n",
    "# Initialize connection to Astra DB\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
    "\n",
    "# Create LangChain LLM and embeddings\n",
    "llm = Groq(api_key=GROQ_API_KEY)  # Groq LLM\n",
    "embedding = OpenAIEmbeddings(openai_api_key=GROQ_API_KEY)  # Change if switching embedding models\n",
    "\n",
    "# Create LangChain vector store backed by Astra DB\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Load the dataset into the vector store\n",
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(f\"Inserted {len(texts[:50])} chunks of text.\")\n",
    "\n",
    "# Create vector store index\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "\n",
    "# QA loop\n",
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    # Query the vector index using Groq LLM\n",
    "    print(f\"\\nQUESTION: \\\"{query_text}\\\"\")\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(f\"ANSWER: \\\"{answer}\\\"\\n\")\n",
    "\n",
    "    # Display documents by relevance\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(f\"    [{score:.4f}] \\\"{doc.page_content[:84]}...\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "import cassio\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch credentials from environment variables\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n",
    "ASTRA_DB_ID = os.getenv('ASTRA_DB_ID')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize Cassandra with Astra DB\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
    "\n",
    "# Initialize LLM and Embeddings\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize the Cassandra-backed vector store\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")\n",
    "\n",
    "# Read the PDF\n",
    "pdfreader = PdfReader('temp.pdf')\n",
    "raw_text = ''\n",
    "for page in pdfreader.pages:\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content\n",
    "\n",
    "# Split text into chunks for indexing\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Insert the split texts into the vector store\n",
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(f\"Inserted {len(texts[:50])} chunks of text.\")\n",
    "\n",
    "# Wrap the vector store in an index wrapper\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "\n",
    "# Question answering loop\n",
    "first_question = True\n",
    "while True:\n",
    "    query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if not query_text:\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(f\"\\nQUESTION: \\\"{query_text}\\\"\")\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(f\"ANSWER: \\\"{answer}\\\"\\n\")\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(f\"    [{score:.4f}] \\\"{doc.page_content[:84]}...\\\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
